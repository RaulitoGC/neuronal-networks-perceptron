\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{titlesec}
\usepackage{url}

\usepackage{amsmath}

\usepackage{tikz}
\usepackage{caption}
\usetikzlibrary{matrix,chains,positioning,decorations.pathreplacing,arrows}

\usepackage{graphicx}
\graphicspath{ {images/} }

\usepackage{url}

\renewcommand{\figurename}{Fig.}

\titleclass{\subsubsubsection}{straight}[\subsection]
\newcounter{subsubsubsection}[subsubsection]
\renewcommand\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}
\renewcommand\theparagraph{\thesubsubsubsection.\arabic{paragraph}}
\titleformat{\subsubsubsection}
  {\normalfont\normalsize\bfseries}{\thesubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsection}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\makeatletter

\def\toclevel@subsubsubsection{4}
\def\l@subsubsubsection{\@dottedtocline{4}{7em}{4em}}

\makeatother

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}


\titleclass{\subsubsubsubsection}{straight}[\subsection]
\newcounter{subsubsubsubsection}[subsubsubsection]
\renewcommand\thesubsubsubsubsection{\thesubsubsubsection.\arabic{subsubsubsubsection}}
\renewcommand\theparagraph{\thesubsubsubsubsection.\arabic{paragraph}}
\titleformat{\subsubsubsubsection}
  {\normalfont\normalsize\bfseries}{\thesubsubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsubsection}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\makeatletter

\def\toclevel@subsubsubsubsection{5}
\def\l@subsubsubsubsection{\@dottedtocline{5}{11em}{4em}}

\makeatother

\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}

\title{}

\begin{document}

\tableofcontents

\section{Introducción}

El cerebro humano es un sistema de cálculo muy complejo, puede llevar a cabo procesamientos que a primera vista parecen sencillos, como por ejemplo, el reconocimiento de imágenes. Esta capacidad que tiene el cerebro humano para pensar, recordar y resolver problemas ha inspirado a muchos científicos a intentar imitar estos funcionamientos.\hfill \break

Los intentos de crear un ordenador que sea capaz de emular estas capacidades ha dado como resultado la aparición de las llamadas Redes Neuronales Artificales o Computación Neuronal.\hfill \break

El principal objetivo del Reconocimiento de patrones es la clasificación ya sea supervisada o no supervisada. Aplicaciones como Data Mining, Web Searching, recuperación de datos multimedia, reconocimiento de rostros, reconocimientos de caracteres escritos a mano, etc., requieren de técnicas de reconocimiento de patrones robustas y eficientes.
Las redes neuronales, por su capacidad de generalización de la información disponible y su tolerancia al ruido, constituyen una herramienta muy útil en la resolución de este tipo de problemas.\cite{patterRecognition}\hfill \break

Este documento muestra los conceptos básicos de las Redes Neuronales y su regla de aprendizaje, en particular la configuración en \textit{Perceptrón Multicapa} y el varios algoritmos de aprendizaje (Propagación hacia atrás,Métodos de segundo orden, RPROP, Algoritmos Genéticos).


\clearpage

\section{Neurona Artificial}
Uno de los retos más importantes a los que se enfrenta el ser humano de nuestra generaciónes el de la construcción de sistemas inteligentes, en su afán de conseguir este propósito aparecen las redes neuronales artificiales. Desde el punto de vista biológico las RNA son un modelo matemático acerca del funcionamiento del cerebro.\textit{"Los sencillos elementosde cálculo aritmético equivalen a las neuronas-células que procesan la información en elcerebro- y la red en general equivale a un conjunto de neuronas conectadas entre sí"} \cite{IA}\hfill \break

Para la raza humana sigue siendo un misterio el funcionamiento del cerebro humano ycomo se genera el pensamiento, sin embargo años y años de investigación han dado ideassobre el accionar del mismo. Si se quieren reproducir las acciones del cerebro humano, sedebe tener la idea de como funciona. Una explicación sencilla y clara se encuentra en \cite{IA}:

\begin{center}
\textit{"Sabemos que la neurona, o célula nerviosa, es la unidad funcional básica de los tejidos del sistema nervioso, incluido el cerebro. Las neuronas están for-madas por el cuerpo de la célula, o soma, en donde se aloja el núcleo de la célula. Del cuerpo de la célula salen ramificaciones de diversas fibras conocidas como dendritas y sale también una fibra más larga denominada axón. Las dendritas se ramifican tejiendo una tupida red alrededor de la célula, mientras el axón se extiende un buen tramo: por lo general, un centímetro (100 veces el diámetro del cuerpo de la célula) y, en casos extremos, hasta un metro. Finalmente, el axón también se ramifica en filamentos y subfilamentos mediante los que establece conexión con las dendritas y los cuerpos de las células de otras neuronas. A la unión o conexión se le conoce como sinapsis. Cada neurona establece sinapsis desde con una docena de otras neuronas hasta con cientos de miles de otras de ellas"}
\end{center}

La neurona articial se ha diseñado como una abstracción de la neurona biológica y se muestra en la Figura \ref{fig:RNA}. La figura representa  la neurona \textit{j} que recibe entradas. Sus partes son:

\clearpage

\begin{figure}[t]
\frame{
\begin{tikzpicture}[
init/.style={
  draw,
  circle,
  inner sep=2pt,
  font=\Huge,
  join = by -latex
},
squa/.style={
  draw,
  inner sep=2pt,
  font=\Large,
  join = by -latex
},
start chain=2,node distance=13mm
]
\node[on chain=2] 
  (x2) {$x_2$};
\node[on chain=2,join=by o-latex] 
  {$w_2$};
\node[on chain=2,init] (sigma) 
  {$\displaystyle\Sigma$};
\node[on chain=2,squa,label=above:{\parbox{2cm}{\centering Función de\\ activación }}]   
  {$f$};
\node[on chain=2,label=above:Salida,join=by -latex] 
  {$y$};
  
\begin{scope}[start chain=1]

\node[on chain=1] at (0,1.5cm) 
  (x1) {$x_1$};
\node[on chain=1,join=by o-latex] 
  (w1) {$w_1$};
  
\end{scope}
\begin{scope}[start chain=3]
\node[on chain=3] at (0,-1.5cm) 
  (x3) {$x_3$};
\node[on chain=3,label=below:Pesos,join=by o-latex] 
  (w3) {$w_3$};
\end{scope}

\node[label=above:\parbox{2cm}{\centering Umbral \\ $b$}] at (sigma|-w1) (wo) {};

\draw[-latex] (w1) -- (sigma);
\draw[-latex] (w3) -- (sigma);
\draw[o-latex] (wo) -- (sigma);

\draw[decorate,decoration={brace,mirror}] (x1.north west) -- node[left=10pt] {Entradas} (x3.south west);

\end{tikzpicture}
}
\centering
\caption{Representacion de una Red Neuronal Artificial.}
\label{fig:RNA}
\end{figure}

\begin{enumerate}
  \item Las \textbf{entradas} $x_i$, que son puntos por los que se reciben los datos provenientes del entorno o bien de otras neuronas. Para este caso se consideran $n$ entradas, siendo el valor de $n=3$
  \[ X = (x_1,x_2,x_3)\]
  
  \item La salida $y_i$. En una neurona biológica corresponde al axón
  \item Al igual que en una neurona biológica, la neurona artificial debe permitir establecer conexiones(sinápsis) entre las entradas(dendritas) de una neurona y la salida (axón) de otra. Esta conexión representa con una línea que tiene asociado un valor llamado \textbf{peso sináptico} $w_ji$. Nótese que el primer subíndice indice la neurona a la que llega la conexión, mientras que el segundo subíndice indica de donde viene la conexión. El peso representa el factor de importancia de la conexión en la determinación del valor de salida. El valor $w_ji$, que es un número real, se modifica durante el entrenamiento de la red neuronal y es la variable de almacenará la información que indicará que la red ha aprendido algo y por tanto que sirva para un propósito u otro.
  
  \item En la Figura \ref{fig:RNA} también se observa una entrada especial, llamada umbral, con un valor fijo que puede ser -1 o 1, y con un peso asociado llamado $w_0$. El valor del umbral se ajusta igual que cualquier otro peso durante el proceso de entrenamiento.
  
  \item Una \textbf{regla de propagación}. Para cierto valor de las entradas $x_i$ y los pesos sinápticos asociados $w_ji$, se realiza algun tipo de operación para obtener el valor del potencial \textit{post-sináptico} . Este valor es función de las entradas y los pesos. Una de las operaciones mas comunes es realizar la suma ponderada, que no es otra cosa que la sumatoria de las entradas, pero teniendo en cuenta la importancia de cada una (el peso sináptico asociado). Luego:


\[u=\sum_{i}^{\ n=3} w_{ji}x_i + w_0b\]


\item Una \textbf{función de activación}. Luego de realizar la suma ponderada, se aplica al resultado la función de activación, que se escoge de tal manera que permita obtener la forma deseada para el valor de la salida.

\begin{equation} \label{eq1}
\begin{split}
y 	&= f(u)\\
	&= f(\sum_{i}^{\ n=3} w_{ji}x_i + w_0b)\\
	&= f(W.X)\\
	&= f(W^TX)
\end{split}
\end{equation}

donde las últimas dos ecuaciones están en notación vectorial.
Es necesario especificar la función de activación $f$. Las funciones más usuales se observan en la  \ref{fig:FUNCACT}

Con estas especificaciones, se puede ahora explicar cómo funciona la neurona. Se supone en el modelo de neurona más simple, que corresponde a la función de activación escalón, tambien llamada limitador duro. En este caso, la salida puede tomar solo dos valores -1 y +1 donde la salida esta determinada por

\begin{equation}\label{eq2}
f(x) = \begin{cases}
             -1  & \text{if } u < 0 \\
             +1  & \text{if } u \ge 0
       \end{cases} \quad
\end{equation}

\clearpage

\begin{figure}[h]
\includegraphics[width=\textwidth]{list_function}
\centering
\caption{Funciones de activación.}
\label{fig:FUNCACT}
\end{figure}

Entonces, para la función sigmoidea, se tiene que

\begin{equation} \label{eq3}
\begin{split}
y 	&= ( \frac{1}{1+e^{-u}}) \\
u	&= \sum_{i}^{\ n=3} w_{ji}x_i + w_0b
\end{split}
\end{equation}

y para el segundo caso de la función sigmoidea

\begin{equation} \label{eq3}
\begin{split}
y 	&= tanh(u) = ( \frac{e^u - e^{-u}}{e^u + e^{-u}}) \\
\end{split}
\end{equation}

La expresión de la ecuación que almacena la neurona en virtud del vector de pesos $W$ es el \textbf{modelo} que representa en mayor o menor grado el comportamiento del vector de salida y con respecto al vector de entrada $X$

\end{enumerate}

Entonces, una neurona artificial es un procesador elemental. Se encarga de procesar un vector de $n$ entradas para producir un único valor de salida $y$. El nivel de activación depende de las entradas recibidas y de los valores sinápticos. Para calcular el estado de activación se ha de calcular en primer lugar la entrada total a la célula. Este valor se cálcula como la suma de todas las entradas ponderadas por ciertos valores dados a la entrada.

\clearpage

\subsection{Redes Neuronales Artificiales}
La capacidad de modelar funciones más complejas aumenta grandemente cuando la neurona no trabaja sola, sino interconectada con otras neuronas, formando Redes Neuronales Artificiales (RNA), tal como se observa de manera simplificada en la Figura \ref{fig:MLP}


\begin{figure}[h]
\frame{
\tikzset{%
  every neuron/.style={
    circle,
    draw,
    minimum size=1cm
  },
  neuron missing/.style={
    draw=none, 
    scale=4,
    text height=0.333cm,
    execute at begin node=\color{black}$\vdots$
  },
}

\begin{tikzpicture}[x=1.5cm, y=1.5cm, >=stealth]

\foreach \m/\l [count=\y] in {1,2,3,missing,4}
  \node [every neuron/.try, neuron \m/.try] (input-\m) at (0,2.5-\y) {};

\foreach \m [count=\y] in {1,missing,2}
  \node [every neuron/.try, neuron \m/.try ] (hidden-\m) at (2,2-\y*1.25) {};

\foreach \m [count=\y] in {1,missing,2}
  \node [every neuron/.try, neuron \m/.try ] (output-\m) at (4,1.5-\y) {};

\foreach \l [count=\i] in {1,2,3,n}
  \draw [<-] (input-\i) -- ++(-1,0)
    node [above, midway] {$I_\l$};

\foreach \l [count=\i] in {1,n}
  \node [above] at (hidden-\i.north) {$H_\l$};

\foreach \l [count=\i] in {1,n}
  \draw [->] (output-\i) -- ++(1,0)
    node [above, midway] {$O_\l$};

\foreach \i in {1,...,4}
  \foreach \j in {1,...,2}
    \draw [->] (input-\i) -- (hidden-\j);

\foreach \i in {1,...,2}
  \foreach \j in {1,...,2}
    \draw [->] (hidden-\i) -- (output-\j);

\foreach \l [count=\x from 0] in {Input, Hidden, Ouput}
  \node [align=center, above] at (\x*2,2) {\l \\ layer};

\end{tikzpicture}

}
\centering
\caption{Topologia de la Red Perceptron Multicapa.}
\label{fig:MLP}
\end{figure}


La red mas simple se llama \textbf{perceptron multicapa}. Esta red define una relación entre las variables de entrada y las variables de salida. Esta relación se obtiene \textit{propagando} hacia adelante los valoers de las variables de entrada. Cada neurona procesa las información recibida por sus entradas y produce una respuesta o activación que se propaga, a través de las conexiones correspondientes, hacia las neuronas de la siguiente capa.\hfill \break

Sea un perceptron multicapa con $C$ capas, de las cuales una es la capa de entrada, una la capa de salida y $C-2$ capas ocultas. Se tiene $n_c$ neuronas en la capa $c$, con $c= 1,2,3,....,C$. sea $W^c = (w_{ji}^c)$ la matriz de pesos asociada a las conexiones de la capa $c$ a la capa $c+1$ para $c=1,2,3,...,C-1$, donde $w_{ji}^c$ representa el peso de la conexión de la neurona $i$ de la capa $C$ a la neurona $j$ de la capa $C+1$. Sea $U^c = (u_j^c)$ el vector de umbrales  de las neuronas de la capa $c$ para $c=2,3,...,C$. Se denota $o_j^c$ a la activación de la neurona $j$ de la capa $c$; estas activaciones se calculan del siguiente modo:



\begin{enumerate}
\item 
Entrada $(o_i^1)$. Estas neuronas transmiten hacia la red las señales recibidas del exterior

\begin{equation} \label{eq4}
o_j^1 = x_j \quad para \quad j=1,2,3,...n_1
\end{equation}

Donde  $X = (x_1,x_2,...,x_n)$ representan el vector de entrada a la red.

\item
Activación de las neuronas de  la capa oculta $c (o_j^c)$: Las neuronas ocutas procesan la informacion recibida aplicando la función de activación $f$ a la suma de los productos de las activaciones que recibe por sus correspondientes pesos:


\begin{equation} \label{eq5}
o_j^c = f(\sum_{i=1}^{\ n_{c-1}} w_{ji}^{c-1}o_i^{c-1} + u_j^c)
\end{equation}

Para $j = 1,2,3,....,n_c \quad y \quad c=2,3,...,c-1$

\item
Salida $(a_i^C)$ : Al igual que en las capas ocultas, la activación de estas neuronas viene dada por la función de activación $f$

\begin{equation} \label{eq6}
y_j = o_j^c = f(\sum_{i=1}^{\ n_{c-1}} w_{ji}^{c-1}o_i^{c-1} + u_j^c)
\end{equation}

Para $j=1,2,3,...,n_c \quad donde \quad Y=(y_1,y_2,,y_3,...,y_c)$ es el vector de salida de la red.

\end{enumerate}

Para el perecptron multicapa las funciones de activación mas usadas son la funciones \textbf{sigmoidal}:

\begin{equation} \label{eq6}
f(u) = \frac{1}{1+e^{-u}})
\end{equation}

y la función \textbf{tangente hiperbólica}

\begin{equation} \label{eq7}
f(u) = ( \frac{1 - e^{-u}}{1 + e^{-u}}) 
\end{equation}

Estas funciones tienen una forma similar pero se diferencian en que la sigmoidal tiene un rango continuo de valores dentro de los intervalor $[0,1]$ mientras que la tangente hiperbólica tiene un rango contínuo en el intervalo $[-1,1]$.


\section{Caso de Estudio}
Todos los días, millones de e-mails invaden las bandejas de entrada de los usuarios de Internet. De todos éstos, una cantidad muy importante es considerada "correo basura". Compuesto por mensajes publicitarios no solicitados, cadenas de la suerte o incluso virus que se autoenvían, el spam afecta a más de un usuario, y
hace que la tarea de revisar el correo sea una verdadera molestia.
El problema fundamental lo representan los spams, que son mensajes publicitarios no solicitados. Ya no resulta raro para quienes contamos con una
dirección de correo electrónico recibir a diario varios mensajes con propagandas de las más variadas temáticas. A pesar de que ningún método de detección de Spam es totalmente efectivo, consideramos que si es posible mejorar los existentes y reducir considerablemente las deficiencias que actualmente presentan las herramientas disponibles. Es un hecho que parte de los mensajes no deseados escapan a los sistemas de detección de correo basura constituyendo así un "falso negativo", igualmente existe la posibilidad de identificar un mensaje como Spam sin serlo, lo que se conoce como "falso positivo". La idea es tomar las máximas precauciones posibles para minimizar este efecto, y para ello se debe ser consciente de este hecho antes de adoptar las posibles medidas de filtrado que se propondrá.\cite{emailspam}
\subsection{Problema}
El crecimiento de Internet a nivel mundial esta cambiando nuestra forma de comunicación entre otros, por lo que cada vez la gente utiliza más el correo electrónico. A causa de un número tentativo de correos electrónicos los publicistas y spammers se ven los modos para obtener un listado grande de correos y así poder enviar spam. Todos los días, billones de e-mails invaden las bandejas de entrada de los usuarios de Internet. De todos éstos, una cantidad muy importante es considerada "correo basura". Compuesto por mensajes publicitarios no solicitados, cadenas de la suerte o incluso virus que se auto envían, el spam aqueja a más de un usuario, y hace que la tarea de revisar correo sea una verdadera molestia.\cite{emailspam}

Los principales problemas son los siguientes:
\begin{enumerate}
\item Perdida de productividad y dinero en las empresas
\item Amenaza la viabilidad de Internet como un medio efectivo de comunicación.
\item Incremento de costos relacionados con el tiempo.
\item Genera importantes costos de seguridad a empresas ISP’s.
\item Incremento de propagación de virus informáticos.
\item Saturación de servidores. Muchos servidores
dedicados para uso privado o para uso general son
congestionados implicando una reducción decalidad
de servicio.
\item Denegación de servicios (Deny of services). Una
cantidad excesiva de correos no deseados puedo
congestionar totalmente el servicio y así denegarlo al
mismo.
\item Buzón de entrada incontrolable por parte del
receptor. Causado por la cantidad masiva que los
spammers envían a los correos electrónicos.
\item Daño de imagen a terceros.
\item Molestias por parte del receptor.
\end{enumerate}

\subsection{Justificacion}
El correo electrónico, es sin duda un medio
que nos permite comunicar rápidamente ofreciéndonos reducción de tiempo y costo Sin
embargo muchas personas aprovechan esto para
utilizarlo de forma no legítima con fines publicitarios,
ocasionando una serie de problemas a
nivel personal comoempresarial.
Como contramedida a esta acción se
necesitan herramientass capaces de reducir el spam.
De esta manera es muy importante la
elaboración de anti-spams, ya que es la forma más
viable de acabar con el spam y ofrecer a los
usuarios seguridad y tranquilidad en los correos
electrónicos, y por otra parte reducir los costos para
las empresas ISP’s y controlar la saturación
de servidores de correo electrónico.
\textbf{El desarrollo de una
herramienta informática capaz de aminorar con los
problemas que causa el spam}, no es solamente capaz
de \textbf{ahorrar mucho dinero} en aquellas empresas que
suelen estar perjudicadas con el spam, sino también es
capaz de permitir una mejor utilización y minimizar
los dolores de cabeza a cualquier usuario del correo
electrónico.\cite{emailspam}
\subsection{Propuestas de Red Neuronal}
asd
\subsubsection{Topologia}
asd
\subsubsection{Reglas}
asd
\subsubsubsection{Regla de propagación}
asd
\subsubsubsection{Regla de Activacion}
asd
\subsubsubsection{Regla de Salida}
asd
\subsubsubsection{Regla de Aprendizaje}
asd
\subsubsubsubsection{Back Propagation}
asd
\subsubsubsubsection{Segundo Orden}
asd
\subsubsubsubsection{R-PROP}
asd

\subsection{Desarrollo de la solucion}
Para el desarrollo del perceptrón multicapa planteado anteriormente hemos se escogio como primera herramienta $R$( Figura \ref{Fig:R}) y con el IDE Rstudio( Figura \ref{Fig:RSTUDIO}), pero no se utilizo  porque \textbf{el tiempo de aprendizaje para un numero mayor de 10 epocas era muy elevado}, a comparacion de la segunda herramienta, python.

\clearpage

\begin{figure}[!htb]
   \begin{minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=.7\linewidth]{rstudio}
     \caption{IDE Rstudio}
     \label{Fig:RSTUDIO}
   \end{minipage}\hfill
   \begin {minipage}{0.48\textwidth}
     \centering
     \includegraphics[width=.7\linewidth]{r}
     \caption{Lenguaje R}
     \label{Fig:R}
   \end{minipage}
\end{figure}

\subsubsection{Herramientas}
Como se dijo anteriormente no se utilizó la herramienta R debido a su alto tiempo en procesar la información, a continuación se describen las herramientas utilizadas.

\subsubsubsection{Python}
Python es un lenguaje de programación interpretado cuya filosofía hace hincapié en una sintaxis que favorezca un código legible.

Se trata de un lenguaje de programación multiparadigma, ya que soporta orientación a objetos, programación imperativa y, en menor medida, programación funcional. Es un lenguaje interpretado, usa tipado dinámico y es multiplataforma.

Es administrado por la Python Software Foundation. Posee una licencia de código abierto, denominada Python Software Foundation License,1 que es compatible con la Licencia pública general de GNU a partir de la versión 2.1.1, e incompatible en ciertas versiones anteriores.\cite{python}

\begin{figure}[h]
\includegraphics[width=3cm, height=3cm]{python}
\centering
\caption{Lenguaje Python.}
\label{fig:FUNCACT}
\end{figure}

\subsubsubsection{PyCharm}
El entorno de desarrollo integrado que se utilizo es PyCharm, es un entorno muy popular utilizado en la comunidad de python que provee una manera sencilla de programar en python eligiendo la version de python que deseamos compilar y agregar los packetes necesarios para el desarrollo de nuestros proyectos.

\begin{figure}[h]
\includegraphics[width=3cm, height=3cm]{pycharm}
\centering
\caption{IDE Pycharm.}
\label{fig:FUNCACT}
\end{figure}

\subsubsubsection{Package}
Para el desarrollo de los algoritmos de aprendizaje para el perceptron multicapa se utilizo una libreria para Inteligencia Artificial llamada NeuPy. Esta libreria actualmente en su version 0.6 soporta diferentes tipos de Redes Neuronales desde un perceptron simple hasta modelos de deep learning \cite{neupy}.

Actualmente soporta la siguientes características:

\begin{enumerate}
\item Deep Learning
\item Reinforcement Learning (RL)
\item Convolutional Neuronal Networks (CNN)
\item Recurrent Neuronal Networks (RNN)
\item Restricted Boltzmann Machine (RBM)
\item Multilayer Perceptron (MLP)
\item Networks based on the Radial Basis Functions (RBFN)
\item Ensemble Networks
\item Competitive Networks
\item Basic Linear Networks
\item Regularizartion Algorithms
\item Step Update Algorithms
\end{enumerate}

\begin{figure}[h]
\includegraphics[width=3.5cm, height=3.5cm]{neupy}
\centering
\caption{Funciones de activación.}
\label{fig:FUNCACT}
\end{figure}

\subsubsection{Implementacion}

\subsubsubsection{Back Propagation}
asd
\subsubsubsection{Segundo Orden}
asd
\subsubsubsection{R-PROP}
asd

\subsection{Resultados}
asd
\subsection{Conclusiones}
asd


\bibliographystyle{unsrt}
\bibliography{bibliography}

\end{document}
